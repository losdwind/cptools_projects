{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Customer Database\n",
    "**This is the first of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Your team has been hired by the company X as data scientists. X makes gadgets for a wide range of industrial and commercial clients.\n",
    "\n",
    "As in-house data scientists, your teams first task, as per request from your new boss, is to optimize business operations. You have decided that a good first step would be to analyze the companys historical sales data to gain a better understanding of where profit is coming from. It may also reveal some low hanging fruit in terms of business opportunities.\n",
    "\n",
    "To get started, you have called the IT department to get access to the customer and sales transactions database. To your horror you've been told that such a database doens't exist, and the only record of sales transactions is kept by John from finance in an Excel spreadsheet. So you've emailed John asking for a CSV dump of the spreadsheet...\n",
    "\n",
    "In this project you need to clean the data you got from John, enrich it with further data, prepare a database for the data, and do some data analysis. The project is comprised of five parts. They are intended to be solved in the order they appear, but it is highly recommended that you read through all of them and devise an overall strategy before you start implementing anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning the data\n",
    "John has emailed you the following link to the CSV dump you requested.\n",
    "\n",
    "- [transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)\n",
    "\n",
    "It seems as though he has been a bit sloppy when keeping the records. \n",
    "\n",
    "In this part you should:\n",
    "- Explain what the data is\n",
    "- Clean it to prepare it for inserting into a database and doing data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the necessary data in our hands, the very first step we need to perform upon the data is to clean it.\n",
    "\n",
    "We will read the data and import the necessary tools for manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76117-001</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1075.82€</td>\n",
       "      <td>2016-01-02 02:32:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44946-1046</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>412.55€</td>\n",
       "      <td>2016-01-02 04:51:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company country          city     price  \\\n",
       "0  54868-5165  Chatterbridge   Spain     Barcelona   784.79€   \n",
       "1  60505-2867           Lajo  Greece  Thessaloniki   187.99€   \n",
       "2   24385-268      Flipstorm  Greece        Athens   221.73€   \n",
       "3   76117-001    Twitterbeat  France        Annecy  1075.82€   \n",
       "4  44946-1046  Chatterbridge   Spain     Barcelona   412.55€   \n",
       "\n",
       "                  date  \n",
       "0  2016-01-02 00:01:05  \n",
       "1  2016-01-02 00:05:26  \n",
       "2  2016-01-02 00:18:30  \n",
       "3  2016-01-02 02:32:30  \n",
       "4  2016-01-02 04:51:55  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check how many total entries (i.e. rows) does the database have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20568"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a quick glance, the datasheet format looks straightforward: 6 different attributes for 20568 entries. However, we should not let jump to conclusions easily.\n",
    "\n",
    "When cleaning data, there are (at least) two main problems we are on the lookout for: __missing values__ and __mistmatched/erroneous entries__. The first problem is much easier to identify than the second. However, we will do our best to thoroughly clean any problems that might come up in the dataset.\n",
    "\n",
    "For that, we need a clear methodology. Without it, one can very easily get lost correcting small problems while overlooking others. A simple quick scroll through the CSV file is allowing us to spot some obvious data errors, however we should not rely only on that.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is why, our methodology here will be to inspect, systematically and programmatically, each column, understand the pattern of values contained in it, and correct for both missing and erroneous errors. We can do this since our column number is relatively small, and it allows for a thorough review of the data contained inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us look at the number of missing values in each column. We should remember that we have a total of 20568 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20568 entries, 0 to 20567\n",
      "Data columns (total 6 columns):\n",
      "part       20558 non-null object\n",
      "company    20568 non-null object\n",
      "country    18397 non-null object\n",
      "city       20535 non-null object\n",
      "price      20567 non-null object\n",
      "date       20568 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 964.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are definitely some missing value issues in our data. More precisely: __columns `part`, `country`, `city` and `price` are having missing entries__ within them. \n",
    "\n",
    "Some of them (such as `country`) clearly have more errors than others. Let us take a look at each column in part, and try to correct for missing values, and eventually erroneous entries as well along the way, as we understand our data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cleaning `part` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what are the missing entries of `part`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Patras</td>\n",
       "      <td>518.38€</td>\n",
       "      <td>2018-02-17 21:43:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14917</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>957.24€</td>\n",
       "      <td>2018-02-17 22:12:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14918</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>966.06€</td>\n",
       "      <td>2018-02-17 22:54:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14919</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Roodel</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Aranhas</td>\n",
       "      <td>873.65€</td>\n",
       "      <td>2018-02-17 23:36:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17524</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Patras</td>\n",
       "      <td>627.32€</td>\n",
       "      <td>2018-07-12 03:28:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17525</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>825.8€</td>\n",
       "      <td>2018-07-12 05:34:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17526</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Gabcube</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Almada</td>\n",
       "      <td>188.31€</td>\n",
       "      <td>2018-07-12 06:49:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17527</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>429.67€</td>\n",
       "      <td>2018-07-12 07:03:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17528</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoonder</td>\n",
       "      <td>United States</td>\n",
       "      <td>Boston</td>\n",
       "      <td>$521.72</td>\n",
       "      <td>2018-07-12 08:38:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17529</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1031.46€</td>\n",
       "      <td>2018-07-12 09:48:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      part      company        country          city     price  \\\n",
       "14916  NaN        Yozio         Greece        Patras   518.38€   \n",
       "14917  NaN  Brainsphere       Portugal         Braga   957.24€   \n",
       "14918  NaN         Lajo         Greece  Thessaloniki   966.06€   \n",
       "14919  NaN       Roodel       Portugal       Aranhas   873.65€   \n",
       "17524  NaN        Yozio         Greece        Patras   627.32€   \n",
       "17525  NaN   Thoughtmix       Portugal     Amadora\\t    825.8€   \n",
       "17526  NaN      Gabcube       Portugal        Almada   188.31€   \n",
       "17527  NaN     Buzzbean        Germany    Düsseldorf   429.67€   \n",
       "17528  NaN      Zoonder  United States        Boston   $521.72   \n",
       "17529  NaN  Twitterbeat         France        Annecy  1031.46€   \n",
       "\n",
       "                      date  \n",
       "14916  2018-02-17 21:43:43  \n",
       "14917  2018-02-17 22:12:24  \n",
       "14918  2018-02-17 22:54:49  \n",
       "14919  2018-02-17 23:36:52  \n",
       "17524  2018-07-12 03:28:46  \n",
       "17525  2018-07-12 05:34:07  \n",
       "17526  2018-07-12 06:49:44  \n",
       "17527  2018-07-12 07:03:50  \n",
       "17528  2018-07-12 08:38:56  \n",
       "17529  2018-07-12 09:48:17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.part.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, there are 10 entries missing here. Initially, we have absolutely no guesses as to how the part numbers might have looked like. \n",
    "\n",
    "__But what if a specific company would produce an overwhelming number of one specific part (with a unique part number)?__ Then, perhaps, we could retrieve the part number from knowing what company we solt the part to. Let's look at the part number distribution for the company 'Yozio'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24286-1562    17\n",
       "62011-0219    14\n",
       "68752-024     13\n",
       "98132-889     13\n",
       "52343-025     13\n",
       "Name: part, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.company == 'Yozio') & (df.country == 'Greece')].part.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is probably __not the case__, since, as we can see, it's almost equally likely to recieve from Yozio part no. _24286-1562_ as it is for part no. _62011-0219_.\n",
    "\n",
    "Therefore, we can't uniquely identify a part number from a company. However, since we can see that we sell multiple kinds of parts to each company, __we may replace the missing values with the part number which is most bought, for each of the 10 companies in part.__ \n",
    "\n",
    "Since this is a sales dataset with ~20000 entries, we can expect that, as long as we have the sales value received from a company, the exact part number for 10 out of 20000 entries is less important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a lambda function to retrieve the top-most index (ie. part number) for the part distribution for all the companies\n",
    "df.loc[df.part.isnull(), 'part'] = df[df.part.isnull()].apply((lambda row: df[(df.company == row.company) & (df.country == row.country) & (df.city == row.city)].part.value_counts().index[0]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us check if we have any more NaN values in our `part` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.part.isnull()].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! They are replaced, and to perform a quick check, let us look at our previous table of missing entries above, take the first index which used to have this problem, and check its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "part                24286-1562\n",
       "company                  Yozio\n",
       "country                 Greece\n",
       "city                    Patras\n",
       "price                  518.38€\n",
       "date       2018-02-17 21:43:43\n",
       "Name: 14916, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[14916]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the result we wanted! :)\n",
    "\n",
    "Lastly, let us understand how the values in this column look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17156-617     301\n",
       "37205-992     295\n",
       "52959-433     295\n",
       "0268-6107     294\n",
       "54868-0823    292\n",
       "62011-0219    291\n",
       "51346-145     289\n",
       "13537-259     288\n",
       "58118-5060    287\n",
       "68084-172     286\n",
       "Name: part, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.part.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51531-9500    126\n",
       "49288-0285    124\n",
       "76117-001     124\n",
       "16477-306     117\n",
       "41167-0843    116\n",
       "49288-0655    115\n",
       "76335-006     109\n",
       "63629-2733    108\n",
       "62742-4030    103\n",
       "59779-028     101\n",
       "Name: part, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.part.value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a quick check-up on the values, nothing seems erroneous regarding their form. Therefore, we consider now to have cleaned the `part` column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cleaning `company` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remember the result outputted from `df.info()` when checking for missing values, we saw that the `company` column had no such errors. \n",
    "\n",
    "In case someone forgot this result, we can check again here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company.isnull()].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that is a good thing. But it does not mean that such a column cannot benefit from data cleaning. More specifically, we need to check for __potential erroneous company names, and correct for them__. \n",
    "\n",
    "Let us look at the company name distribution across this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " -                  1\n",
       " a                  1\n",
       "Avaveo            212\n",
       "Brainsphere      1242\n",
       "Bubblemix          54\n",
       "Buzzbean         1254\n",
       "Chatterbridge    1589\n",
       "Eimbee            498\n",
       "Flipstorm        1193\n",
       "Gabcube           357\n",
       "Gabtune            27\n",
       "Gevee              36\n",
       "Innojam            44\n",
       "Kanoodle          127\n",
       "Laj0                1\n",
       "Lajo              220\n",
       "Ntags            1514\n",
       "Ntagz               1\n",
       "Realpoint         158\n",
       "Rhycero           204\n",
       "Riffpath          151\n",
       "Roodel            627\n",
       "Shufflebeat      1553\n",
       "Tagtune            12\n",
       "Teklist           428\n",
       "Thoughtmix       2795\n",
       "Thoughtmixz         1\n",
       "Twitterbeat      2268\n",
       "Voomm             250\n",
       "Wordify           968\n",
       "Yozio             655\n",
       "Zoonder           454\n",
       "Zooxo            1670\n",
       "Zooxo.              2\n",
       "aa                  1\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.company.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see multiple problems (__7 in total__): ` -`, ` a` and `aa` are obviously not valid company names, while `Laj0`, `Ntagz`, `Thoughtmixz` and `Zooxo.` are misspelled versions of their counter parts. How did we find out (besides the obvious name)? We look at company names which only show up _1 or 2 times_. It is likely that such entries are outliers which need to be inspected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what approach to take for cleaning this data?\n",
    "\n",
    "For the misspelled company names, it is quite easy and safe to replace their names with the original ones, since we see such strong similarities between the two strings. \n",
    "\n",
    "However, for ` -`, ` a` and `aa`, we don't have a guess. Instead, what we have decided to do is to __inspect the country and city from where that company is__, since it is likely that we are only selling parts to one main company in a specific city of a country (we don't know that, but we will check now for this assumption)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>37205-992</td>\n",
       "      <td>a</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York</td>\n",
       "      <td>$395.3</td>\n",
       "      <td>2017-12-16 18:59:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part company        country      city   price                 date\n",
       "13840  37205-992       a  United States  New York  $395.3  2017-12-16 18:59:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == ' a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13841</th>\n",
       "      <td>51346-145</td>\n",
       "      <td>aa</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York</td>\n",
       "      <td>$1059.38</td>\n",
       "      <td>2017-12-16 20:02:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part company        country      city     price  \\\n",
       "13841  51346-145      aa  United States  New York  $1059.38   \n",
       "\n",
       "                      date  \n",
       "13841  2017-12-16 20:02:15  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'aa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, both are operating from the United States, New York. \n",
    "\n",
    "What other companies with which we collaborate do operate in the exact same area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wordify    856\n",
       " a           1\n",
       "aa           1\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.country == 'United States') & (df.city == 'New York')].company.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the company Wordify... This is great news! It appears that our instinct was correct, and if this is the case, then we can safely replace the name of `a` and `aa` with the company that we do most business with, from the area of US, city of New York.\n",
    "\n",
    "We will change the data below, for both anomalies at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.company == ' a') | (df.company == 'aa'), 'company'] = df[(df.country == 'United States') & (df.city == 'New York')].company.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next off, we will repeat the same method to the `-` company name entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>17156-617</td>\n",
       "      <td>-</td>\n",
       "      <td>United States</td>\n",
       "      <td>Boston</td>\n",
       "      <td>$1168.82</td>\n",
       "      <td>2017-12-16 17:55:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part company        country    city     price                 date\n",
       "13839  17156-617       -  United States  Boston  $1168.82  2017-12-16 17:55:55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == ' -']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zoonder    397\n",
       " -           1\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.country == 'United States') & (df.city == 'Boston')].company.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our hunch was right. Only Zoonder operates in that area, which means we can replace the otherwise-unguessable name of `-` with Zoonder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.company == ' -'), 'company'] = df[(df.country == 'United States') & (df.city == 'Boston')].company.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last 4 erroneous entries which we can guess the necessary name change for, we will __quickly scan (with our eyes) the country and city__ for each such company, in order to make sure that they correspond with the data to which we want to adhere them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24286-1562</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>317.65€</td>\n",
       "      <td>2016-01-02 11:01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>55154-5057</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>83.18€</td>\n",
       "      <td>2016-01-18 08:30:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>52959-433</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>327.3€</td>\n",
       "      <td>2016-01-21 03:43:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>52959-433</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>343.21€</td>\n",
       "      <td>2016-01-23 01:01:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           part company country          city    price                 date\n",
       "1    60505-2867    Lajo  Greece  Thessaloniki  187.99€  2016-01-02 00:05:26\n",
       "9    24286-1562    Lajo  Greece  Thessaloniki  317.65€  2016-01-02 11:01:32\n",
       "375  55154-5057    Lajo  Greece  Thessaloniki   83.18€  2016-01-18 08:30:06\n",
       "441   52959-433    Lajo  Greece  Thessaloniki   327.3€  2016-01-21 03:43:32\n",
       "492   52959-433    Lajo  Greece  Thessaloniki  343.21€  2016-01-23 01:01:50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Lajo'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12882</th>\n",
       "      <td>54123-957</td>\n",
       "      <td>Laj0</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>189.29€</td>\n",
       "      <td>2017-10-24 06:22:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part company country          city    price                 date\n",
       "12882  54123-957    Laj0  Greece  Thessaloniki  189.29€  2017-10-24 06:22:42"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Laj0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the same company, so we'll make a quick name fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.company == 'Laj0'), 'company'] = 'Lajo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for `Ntagz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>62756-707</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>322.45€</td>\n",
       "      <td>2016-01-03 13:12:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49349-842</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>269.46€</td>\n",
       "      <td>2016-01-04 05:19:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>21695-267</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>361.54€</td>\n",
       "      <td>2016-01-04 21:36:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>68084-172</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>564.39€</td>\n",
       "      <td>2016-01-05 02:14:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>68180-121</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>1028.04€</td>\n",
       "      <td>2016-01-05 02:33:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part company   country    city     price                 date\n",
       "31  62756-707   Ntags  Portugal  Lisbon   322.45€  2016-01-03 13:12:09\n",
       "48  49349-842   Ntags  Portugal  Lisbon   269.46€  2016-01-04 05:19:44\n",
       "66  21695-267   Ntags  Portugal  Lisbon   361.54€  2016-01-04 21:36:57\n",
       "70  68084-172   Ntags  Portugal  Lisbon   564.39€  2016-01-05 02:14:55\n",
       "71  68180-121   Ntags  Portugal  Lisbon  1028.04€  2016-01-05 02:33:00"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Ntags'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>68084-172</td>\n",
       "      <td>Ntagz</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>670.96€</td>\n",
       "      <td>2017-10-25 14:12:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part company   country    city    price                 date\n",
       "12905  68084-172   Ntagz  Portugal  Lisbon  670.96€  2017-10-25 14:12:44"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Ntagz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.company == 'Ntagz'), 'company'] = 'Ntags'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for `Thoughtmixz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0268-6107</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>477.71€</td>\n",
       "      <td>2016-01-02 18:52:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>76117-001</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>1146.85€</td>\n",
       "      <td>2016-01-03 10:48:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>41163-428</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>120.64€</td>\n",
       "      <td>2016-01-03 16:16:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>54868-0823</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>163.6€</td>\n",
       "      <td>2016-01-03 19:48:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>51079-947</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>600.24€</td>\n",
       "      <td>2016-01-04 08:46:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          part     company   country       city     price                 date\n",
       "15   0268-6107  Thoughtmix  Portugal  Amadora\\t   477.71€  2016-01-02 18:52:45\n",
       "27   76117-001  Thoughtmix  Portugal  Amadora\\t  1146.85€  2016-01-03 10:48:11\n",
       "33   41163-428  Thoughtmix  Portugal  Amadora\\t   120.64€  2016-01-03 16:16:24\n",
       "35  54868-0823  Thoughtmix  Portugal  Amadora\\t    163.6€  2016-01-03 19:48:44\n",
       "52   51079-947  Thoughtmix  Portugal  Amadora\\t   600.24€  2016-01-04 08:46:27"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Thoughtmix'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19823</th>\n",
       "      <td>49738-105</td>\n",
       "      <td>Thoughtmixz</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>506.82€</td>\n",
       "      <td>2018-11-19 16:04:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part      company   country       city    price  \\\n",
       "19823  49738-105  Thoughtmixz  Portugal  Amadora\\t  506.82€   \n",
       "\n",
       "                      date  \n",
       "19823  2018-11-19 16:04:40  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Thoughtmixz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.company == 'Thoughtmixz'), 'company'] = 'Thoughtmix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for `Zooxo.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54092-515</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£704.94</td>\n",
       "      <td>2016-01-02 09:09:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>67544-356</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£602.37</td>\n",
       "      <td>2016-01-03 00:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13537-468</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£449.23</td>\n",
       "      <td>2016-01-05 03:29:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>17156-617</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£1100.73</td>\n",
       "      <td>2016-01-06 00:55:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0228-2167</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£932.22</td>\n",
       "      <td>2016-01-06 05:59:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          part company         country    city     price                 date\n",
       "8    54092-515   Zooxo  United Kingdom  London   £704.94  2016-01-02 09:09:01\n",
       "21   67544-356   Zooxo  United Kingdom  London   £602.37  2016-01-03 00:49:00\n",
       "72   13537-468   Zooxo  United Kingdom  London   £449.23  2016-01-05 03:29:13\n",
       "91   17156-617   Zooxo  United Kingdom  London  £1100.73  2016-01-06 00:55:19\n",
       "100  0228-2167   Zooxo  United Kingdom  London   £932.22  2016-01-06 05:59:08"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Zooxo'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12698</th>\n",
       "      <td>35356-325</td>\n",
       "      <td>Zooxo.</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£32.84</td>\n",
       "      <td>2017-10-12 20:13:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12700</th>\n",
       "      <td>51346-126</td>\n",
       "      <td>Zooxo.</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£149.96</td>\n",
       "      <td>2017-10-12 21:17:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part company         country    city    price                 date\n",
       "12698  35356-325  Zooxo.  United Kingdom  London   £32.84  2017-10-12 20:13:59\n",
       "12700  51346-126  Zooxo.  United Kingdom  London  £149.96  2017-10-12 21:17:13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Zooxo.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.company == 'Zooxo.'), 'company'] = 'Zooxo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us look again at our cleaned `company` name column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Avaveo            212\n",
       "Brainsphere      1242\n",
       "Bubblemix          54\n",
       "Buzzbean         1254\n",
       "Chatterbridge    1589\n",
       "Eimbee            498\n",
       "Flipstorm        1193\n",
       "Gabcube           357\n",
       "Gabtune            27\n",
       "Gevee              36\n",
       "Innojam            44\n",
       "Kanoodle          127\n",
       "Lajo              221\n",
       "Ntags            1515\n",
       "Realpoint         158\n",
       "Rhycero           204\n",
       "Riffpath          151\n",
       "Roodel            627\n",
       "Shufflebeat      1553\n",
       "Tagtune            12\n",
       "Teklist           428\n",
       "Thoughtmix       2796\n",
       "Twitterbeat      2268\n",
       "Voomm             250\n",
       "Wordify           970\n",
       "Yozio             655\n",
       "Zoonder           455\n",
       "Zooxo            1672\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.company.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems clear and legitimate, and none of the names are only met once or twice. We will therefore conclude our cleaning efforts upon the `company` column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Cleaning `country` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column is the one which suffers most from missing entries, more precisely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2171"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.country.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2171 missing entries!_ That can't be good. Before tackling this important issue, let's try to understand our 'country' data and fix any potential erroneous data.\n",
    "\n",
    "For that, we have considered that a table representation of company names __grouped by their operating country__ will make visualization of data much more straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company        country       \n",
      "Avaveo         France             182\n",
      "Brainsphere    Portuga              1\n",
      "               Portugal          1115\n",
      "Bubblemix      Japan               47\n",
      "Buzzbean       Germany           1125\n",
      "               Tyskland             1\n",
      "Chatterbridge  Spain             1425\n",
      "Eimbee         France             452\n",
      "Flipstorm      France             332\n",
      "               Greece             713\n",
      "Gabcube        Portugal           324\n",
      "Gabtune        France              24\n",
      "Gevee          France              35\n",
      "Innojam        Netherlands         40\n",
      "Kanoodle       Japan              112\n",
      "Lajo           Greece             202\n",
      "Ntags          Portuga              1\n",
      "               Portugal          1352\n",
      "Realpoint      Portugal           143\n",
      "Rhycero        France             180\n",
      "Riffpath       Greece             130\n",
      "Roodel         Portugal           554\n",
      "Shufflebeat    Portugal          1382\n",
      "Tagtune        Switzerland         11\n",
      "Teklist        Netherlands        387\n",
      "Thoughtmix     Portuga              3\n",
      "               Portugal          2510\n",
      "Twitterbeat    France            2038\n",
      "Voomm          France             220\n",
      "Wordify        United States      858\n",
      "Yozio          Greece             585\n",
      "Zoonder        US                   1\n",
      "               United States      398\n",
      "Zooxo          United Kingdom    1511\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['company', 'country']).city.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we study the above table for a bit, it becomes easy to see that __almost all companies operate in only one country__, with a sole exception of ___Flipstorm___, which operates both in France and in Greece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we see 3 immediate problems needing correction: \n",
    "\n",
    "1. `Portugal` is sometimes misspelled as `Portuga`\n",
    "2. In one instance, `Germany` has been referred to as `Tyskland`\n",
    "3. In one instance, `United States` has been referred to as `US`.\n",
    "\n",
    "These three fixes are straightforward, since we know exactly what string is the error and what should it be replaced by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.country == 'Portuga', 'country'] = 'Portugal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.country == 'Tyskland', 'country'] = 'Germany'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.country == 'US', 'country'] = 'United States'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we should have fixed all the misspelling errors from the `country` column, let us check it again within a grouping _by `company` and `country`_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company        country       \n",
      "Avaveo         France             182\n",
      "Brainsphere    Portugal          1116\n",
      "Bubblemix      Japan               47\n",
      "Buzzbean       Germany           1126\n",
      "Chatterbridge  Spain             1425\n",
      "Eimbee         France             452\n",
      "Flipstorm      France             332\n",
      "               Greece             713\n",
      "Gabcube        Portugal           324\n",
      "Gabtune        France              24\n",
      "Gevee          France              35\n",
      "Innojam        Netherlands         40\n",
      "Kanoodle       Japan              112\n",
      "Lajo           Greece             202\n",
      "Ntags          Portugal          1353\n",
      "Realpoint      Portugal           143\n",
      "Rhycero        France             180\n",
      "Riffpath       Greece             130\n",
      "Roodel         Portugal           554\n",
      "Shufflebeat    Portugal          1382\n",
      "Tagtune        Switzerland         11\n",
      "Teklist        Netherlands        387\n",
      "Thoughtmix     Portugal          2513\n",
      "Twitterbeat    France            2038\n",
      "Voomm          France             220\n",
      "Wordify        United States      858\n",
      "Yozio          Greece             585\n",
      "Zoonder        United States      399\n",
      "Zooxo          United Kingdom    1511\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['company', 'country']).city.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>France</td>\n",
       "      <td>Nanterre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country      city\n",
       "2   Greece    Athens\n",
       "12  France  Nanterre"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.company == 'Flipstorm'][['country', 'city']].dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to be in order! Now we can clearly see the pattern that all companies except ___Flipstorm___ operate in exactly 1 country.\n",
    "\n",
    "This will help us tremendously in fixing the many NaN values that we have identfied within this column. \n",
    "We may now check for a specific company and its operating city, and if both these values are present, we will be able to immediately determine which country data was missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the \"company - country\" grouping has one-to-one mappings for all values except for Flipstorm, we can make a dictionary storing the expected operating country for all the companies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Avaveo': 'France',\n",
       " 'Brainsphere': 'Portugal',\n",
       " 'Bubblemix': 'Japan',\n",
       " 'Buzzbean': 'Germany',\n",
       " 'Chatterbridge': 'Spain',\n",
       " 'Eimbee': 'France',\n",
       " 'Flipstorm': 'Greece',\n",
       " 'Gabcube': 'Portugal',\n",
       " 'Gabtune': 'France',\n",
       " 'Gevee': 'France',\n",
       " 'Innojam': 'Netherlands',\n",
       " 'Kanoodle': 'Japan',\n",
       " 'Lajo': 'Greece',\n",
       " 'Ntags': 'Portugal',\n",
       " 'Realpoint': 'Portugal',\n",
       " 'Rhycero': 'France',\n",
       " 'Riffpath': 'Greece',\n",
       " 'Roodel': 'Portugal',\n",
       " 'Shufflebeat': 'Portugal',\n",
       " 'Tagtune': 'Switzerland',\n",
       " 'Teklist': 'Netherlands',\n",
       " 'Thoughtmix': 'Portugal',\n",
       " 'Twitterbeat': 'France',\n",
       " 'Voomm': 'France',\n",
       " 'Wordify': 'United States',\n",
       " 'Yozio': 'Greece',\n",
       " 'Zoonder': 'United States',\n",
       " 'Zooxo': 'United Kingdom'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_country_dict = dict(df.groupby(['company', 'country']).city.count().index)\n",
    "company_country_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like just what we needed. We need to treat the special case of Flipstorm separately, since it appears that the dictionary has only saved one of the two possible countries in its structure.\n",
    "\n",
    "To not complicate ourselves, let us just remove the entry corresponding to Flipstorm from the dict, since we will treat the case separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_country_dict.pop('Flipstorm'); # Remove Flipstorm from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_country_wrangle(row):\n",
    "    if (row.company != 'Flipstorm'):\n",
    "        row.country = company_country_dict.get(row.company)\n",
    "    else:\n",
    "        if (row.city == 'Athens'):\n",
    "            row.country = 'Greece'\n",
    "        elif (row.city == 'Nanterre'):\n",
    "            row.country = 'France'\n",
    "    return row\n",
    "\n",
    "# Iterate efficiently over each row of the dataframe using the apply() method\n",
    "df[df.country.isnull()] = df[df.country.isnull()].apply(df_country_wrangle, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have performed our efficient replacement of the missing values with the original countries, let's look at our 'company-country' grouped table and see if how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company        country       \n",
      "Avaveo         France             212\n",
      "Brainsphere    Portugal          1238\n",
      "Bubblemix      Japan               54\n",
      "Buzzbean       Germany           1254\n",
      "Chatterbridge  Spain             1589\n",
      "Eimbee         France             498\n",
      "Flipstorm      France             381\n",
      "               Greece             812\n",
      "Gabcube        Portugal           357\n",
      "Gabtune        France              27\n",
      "Gevee          France              36\n",
      "Innojam        Netherlands         44\n",
      "Kanoodle       Japan              126\n",
      "Lajo           Greece             221\n",
      "Ntags          Portugal          1509\n",
      "Realpoint      Portugal           158\n",
      "Rhycero        France             204\n",
      "Riffpath       Greece             151\n",
      "Roodel         Portugal           627\n",
      "Shufflebeat    Portugal          1550\n",
      "Tagtune        Switzerland         12\n",
      "Teklist        Netherlands        426\n",
      "Thoughtmix     Portugal          2788\n",
      "Twitterbeat    France            2267\n",
      "Voomm          France             250\n",
      "Wordify        United States      968\n",
      "Yozio          Greece             653\n",
      "Zoonder        United States      454\n",
      "Zooxo          United Kingdom    1669\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['company', 'country']).city.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.country.isnull()].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks just as we would have hoped. It also appears that the distribuion of countries for each company has been well preserved. We have finalized the cleaning of the `country` column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Cleaning `city` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will turn our attention towards missing values and erroneous values.\n",
    "\n",
    "Let's check the number of missing values, and which companies do they correspond to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.city.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brainsphere    4\n",
       "Kanoodle       1\n",
       "Ntags          6\n",
       "Shufflebeat    3\n",
       "Teklist        2\n",
       "Thoughtmix     8\n",
       "Twitterbeat    1\n",
       "Wordify        2\n",
       "Yozio          2\n",
       "Zoonder        1\n",
       "Zooxo          3\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city.isnull()].company.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. Considering our previous results, we can have the hope that a similar thing may happen again, such that a company would mainly operate in only one city of a country.\n",
    "\n",
    "Let us check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company        city        \n",
      "Avaveo         Nice             212\n",
      "Brainsphere    Braga           1237\n",
      "               Monção             1\n",
      "Bubblemix      Asaka             54\n",
      "Buzzbean       Düsseldorf      1254\n",
      "Chatterbridge  Barcelona       1589\n",
      "Eimbee         Amiens           498\n",
      "Flipstorm      Athens           812\n",
      "               Nanterre         381\n",
      "Gabcube        Almada           357\n",
      "Gabtune        Lyon              27\n",
      "Gevee          Champagnole       36\n",
      "Innojam        Amsterdam         44\n",
      "Kanoodle       Niihama          126\n",
      "Lajo           Thessaloniki     221\n",
      "Ntags          Lisbon          1509\n",
      "Realpoint      Lisbon           158\n",
      "Rhycero        Arcueil          204\n",
      "Riffpath       Heraklion        151\n",
      "Roodel         Aranhas          627\n",
      "Shufflebeat    Porto           1550\n",
      "Tagtune        Zürich            12\n",
      "Teklist        Arnhem           426\n",
      "Thoughtmix     Amadora\\t       2787\n",
      "               Vila Fria          1\n",
      "Twitterbeat    Annecy          2267\n",
      "Voomm          Paris            250\n",
      "Wordify        New York         968\n",
      "Yozio          Patras           653\n",
      "Zoonder        Boston           454\n",
      "Zooxo          London          1669\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['company', 'city']).country.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is within our intuition. We can observe that the vast majority of companies (_with sole exceptions of `Brainsphere`, `Flipstorm` and `Thoughtmix`_) only operate in one city of a country, making it easier to repeat the same cleaning pattern as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to be careful. Here we can see that `Brainsphere` and `Thoughtmix` have somewhat of an outlier in their city distribution, since _Monção_ and _Vila Fria_ are only met once within the whole dataset. However, after performing an online search, we have found that both these cities are indeed in Portugal, which is correctly corresponding to the country in which these companies operate. \n",
    "\n",
    "Is it a mistake, or simply an outlier? We cannot know, however it is possible that, since the location of the country and the city match, it can be just an irregular business trade, and there is no further need to correct it.\n",
    "\n",
    "However, what if we have a missing city value corresponding to `Brainsphere` or `Thoughtmix`? In that case, we believe we can safely assume that the city involved in the trade would be the high-frequency one, and not the outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Avaveo': 'Nice',\n",
       " 'Brainsphere': 'Monção',\n",
       " 'Bubblemix': 'Asaka',\n",
       " 'Buzzbean': 'Düsseldorf',\n",
       " 'Chatterbridge': 'Barcelona',\n",
       " 'Eimbee': 'Amiens',\n",
       " 'Flipstorm': 'Nanterre',\n",
       " 'Gabcube': 'Almada',\n",
       " 'Gabtune': 'Lyon',\n",
       " 'Gevee': 'Champagnole',\n",
       " 'Innojam': 'Amsterdam',\n",
       " 'Kanoodle': 'Niihama',\n",
       " 'Lajo': 'Thessaloniki',\n",
       " 'Ntags': 'Lisbon',\n",
       " 'Realpoint': 'Lisbon',\n",
       " 'Rhycero': 'Arcueil',\n",
       " 'Riffpath': 'Heraklion',\n",
       " 'Roodel': 'Aranhas',\n",
       " 'Shufflebeat': 'Porto',\n",
       " 'Tagtune': 'Zürich',\n",
       " 'Teklist': 'Arnhem',\n",
       " 'Thoughtmix': 'Vila Fria',\n",
       " 'Twitterbeat': 'Annecy',\n",
       " 'Voomm': 'Paris',\n",
       " 'Wordify': 'New York',\n",
       " 'Yozio': 'Patras',\n",
       " 'Zoonder': 'Boston',\n",
       " 'Zooxo': 'London'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_city_dict = dict(df.groupby(['company', 'city']).country.count().index)\n",
    "company_city_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to be careful here so that `Brainsphere` and `Thoughtmix` have the correct values attached to their keys. Once again, `Flipstorm` should be removed from the dictionary, since we cannot make a safe guess about its operating city based on just the company name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_city_dict.pop('Flipstorm');\n",
    "\n",
    "company_city_dict['Brainsphere'] = 'Braga'\n",
    "company_city_dict['Thoughtmix'] = 'Amadora'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we looked at the company names having NaN city entries before, and we didn't find the company `Flipstorm` between them, we are not required to treat its case for this dataset.\n",
    "\n",
    "Once again, we can iterate over the rows of the city-missing values subset of the dataframe, and add the cities depending on the found company names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_city_wrangle(row):\n",
    "    if (row.city != 'Flipstorm'):\n",
    "        row.city = company_city_dict.get(row.company)\n",
    "    return row\n",
    "\n",
    "# Iterate efficiently over each row of the dataframe using the apply() method\n",
    "df[df.city.isnull()] = df[df.city.isnull()].apply(df_city_wrangle, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city.isnull()].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have mended the missing data. Let's look back at the previous table to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company        city        \n",
      "Avaveo         Nice             212\n",
      "Brainsphere    Braga           1241\n",
      "               Monção             1\n",
      "Bubblemix      Asaka             54\n",
      "Buzzbean       Düsseldorf      1254\n",
      "Chatterbridge  Barcelona       1589\n",
      "Eimbee         Amiens           498\n",
      "Flipstorm      Athens           812\n",
      "               Nanterre         381\n",
      "Gabcube        Almada           357\n",
      "Gabtune        Lyon              27\n",
      "Gevee          Champagnole       36\n",
      "Innojam        Amsterdam         44\n",
      "Kanoodle       Niihama          127\n",
      "Lajo           Thessaloniki     221\n",
      "Ntags          Lisbon          1515\n",
      "Realpoint      Lisbon           158\n",
      "Rhycero        Arcueil          204\n",
      "Riffpath       Heraklion        151\n",
      "Roodel         Aranhas          627\n",
      "Shufflebeat    Porto           1553\n",
      "Tagtune        Zürich            12\n",
      "Teklist        Arnhem           428\n",
      "Thoughtmix     Amadora            8\n",
      "               Amadora\\t       2787\n",
      "               Vila Fria          1\n",
      "Twitterbeat    Annecy          2268\n",
      "Voomm          Paris            250\n",
      "Wordify        New York         970\n",
      "Yozio          Patras           655\n",
      "Zoonder        Boston           455\n",
      "Zooxo          London          1672\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['company', 'city']).country.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is exactly the result that we have hoped for, and the cities were now added to the dataset.\n",
    "\n",
    "Lastly for wrangling this column, when looking at the `Thoughtmix` company, it can be seen that it's most common city, _Amadora_, is unproperly encoded, since it contains (in most cases) an extra tab. We can easily clean for that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.city == 'Amadora\\t', 'city'] = 'Amadora' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check one more time, to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company        city        \n",
      "Avaveo         Nice             212\n",
      "Brainsphere    Braga           1241\n",
      "               Monção             1\n",
      "Bubblemix      Asaka             54\n",
      "Buzzbean       Düsseldorf      1254\n",
      "Chatterbridge  Barcelona       1589\n",
      "Eimbee         Amiens           498\n",
      "Flipstorm      Athens           812\n",
      "               Nanterre         381\n",
      "Gabcube        Almada           357\n",
      "Gabtune        Lyon              27\n",
      "Gevee          Champagnole       36\n",
      "Innojam        Amsterdam         44\n",
      "Kanoodle       Niihama          127\n",
      "Lajo           Thessaloniki     221\n",
      "Ntags          Lisbon          1515\n",
      "Realpoint      Lisbon           158\n",
      "Rhycero        Arcueil          204\n",
      "Riffpath       Heraklion        151\n",
      "Roodel         Aranhas          627\n",
      "Shufflebeat    Porto           1553\n",
      "Tagtune        Zürich            12\n",
      "Teklist        Arnhem           428\n",
      "Thoughtmix     Amadora         2795\n",
      "               Vila Fria          1\n",
      "Twitterbeat    Annecy          2268\n",
      "Voomm          Paris            250\n",
      "Wordify        New York         970\n",
      "Yozio          Patras           655\n",
      "Zoonder        Boston           455\n",
      "Zooxo          London          1672\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['company', 'city']).country.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it really looks clean and neat!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Cleaning `price` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a cleaning on the `price` column can be a tricky task.\n",
    "\n",
    "First of all, one of the biggest problems that we have with this data, in terms of usability, is that it's not consistent, as the selling prices are stored in various different currencies. However, we will leave this fix for the Data Enrichment/Augmentation part, since we need more information about exact conversion rates on specific dates before we can reach a correct estimate of all the different prices.\n",
    "\n",
    "For now, let us __only__ focus on cleaning the price data itself. \n",
    "\n",
    "It is worth mentioning here that __the information stored in this column is definitory for our sales database__. Therefore, since we cannot guess a certain transaction's price, if we do find missing or erroneous price information for an entry, we argue that __it's in our best interest to remove such an entry from the dataset.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok then, so first, how many dataset rows have missing price values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11015</th>\n",
       "      <td>49967-724</td>\n",
       "      <td>Roodel</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Aranhas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-11 08:00:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part company   country     city price                 date\n",
       "11015  49967-724  Roodel  Portugal  Aranhas   NaN  2017-07-11 08:00:56"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.price.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really good, only one entry has a missing price. Since we could not possibly guess what the total transaction value might have been, this entry is not relevant for this dataset, so we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.price.isnull()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that was it for the missing values. But can we expect the `prices` column to be completely error-free now? Probably not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wanting to investigate such a column, we realized that __the most important parts of the price string are its beginning character and its ending character__. This is partly because that is where the currency char should be found, and partly because, if there is anything else besides a number or a currency char, then the price is probably erroneous. _Let's check!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$    1425\n",
       "-      61\n",
       "1    3966\n",
       "2    1929\n",
       "3    1630\n",
       "4    2086\n",
       "5    1493\n",
       "6    1403\n",
       "7    1674\n",
       "8    1635\n",
       "9    1407\n",
       "n       3\n",
       "v       2\n",
       "£    1672\n",
       "¥     181\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This search takes the *first* char of all the price strings and counts their frequency (also, I sorted them by their encoding index position)\n",
    "\n",
    "df.price.str[0].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-        5\n",
       "0       34\n",
       "1      373\n",
       "2      361\n",
       "3      372\n",
       "4      334\n",
       "5      370\n",
       "6      358\n",
       "7      354\n",
       "8      366\n",
       "9      360\n",
       "a        3\n",
       "d        2\n",
       "€    17275\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This search takes the *last* char of all the price strings and counts their frequency (also, I sorted them by their encoding index position)\n",
    "\n",
    "df.price.str[-1].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we uncover from this search?\n",
    "\n",
    "1. We now know that all the currencies within this dataset are the **_dollar_**, **_euro_**, **_pound_** and **_yen_**.\n",
    "    * Since we know in what countries our partner companies reside, we can understand that those currencies are the __USD__ (we only have United States purchases for the dollar), __EUR__, __GBP__ and __JPY__ (we only have Japanese purchases for the yen).\n",
    "    \n",
    "2. There are 5 entries which end in `-`. That does not look like a correct price marker.\n",
    "\n",
    "3. There are 3 price entries that start with `n` and end in `a`, and 2 price entries that start with `v` and end with `d`. Those are probably not valid prices.\n",
    "\n",
    "We will investigate further points 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to tackle the entries ending in `-` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8683</th>\n",
       "      <td>49349-820</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-03-03 15:24:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8684</th>\n",
       "      <td>10267-2529</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-03-03 18:07:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>13537-259</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-03-03 19:08:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>41163-428</td>\n",
       "      <td>Avaveo</td>\n",
       "      <td>France</td>\n",
       "      <td>Nice</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-06-02 07:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>52959-433</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-06-02 09:04:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             part        company   country        city price  \\\n",
       "8683    49349-820  Chatterbridge     Spain   Barcelona     -   \n",
       "8684   10267-2529     Thoughtmix  Portugal     Amadora     -   \n",
       "8685    13537-259          Ntags  Portugal      Lisbon     -   \n",
       "10329   41163-428         Avaveo    France        Nice     -   \n",
       "10330   52959-433       Buzzbean   Germany  Düsseldorf     -   \n",
       "\n",
       "                      date  \n",
       "8683   2017-03-03 15:24:39  \n",
       "8684   2017-03-03 18:07:56  \n",
       "8685   2017-03-03 19:08:54  \n",
       "10329  2017-06-02 07:04:35  \n",
       "10330  2017-06-02 09:04:46  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.price.str[-1] == '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are apparently other entries with a missing selling price, just with another missing value identificator.\n",
    "\n",
    "As mentioned before, we do not need entries without price indicators, therefore we will drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.price.str[-1] == '-'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next in our investigation, let's look for the prices with letters in them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11155</th>\n",
       "      <td>35356-325</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>na</td>\n",
       "      <td>2017-07-19 00:55:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11156</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>na</td>\n",
       "      <td>2017-07-19 01:34:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11157</th>\n",
       "      <td>59779-601</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>na</td>\n",
       "      <td>2017-07-19 01:45:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part      company   country     city price                 date\n",
       "11155  35356-325   Thoughtmix  Portugal  Amadora    na  2017-07-19 00:55:13\n",
       "11156  24385-268  Twitterbeat    France   Annecy    na  2017-07-19 01:34:53\n",
       "11157  59779-601   Thoughtmix  Portugal  Amadora    na  2017-07-19 01:45:59"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.price.str.find('n') >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>68084-172</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>void</td>\n",
       "      <td>2017-03-18 01:53:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>54868-0823</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>void</td>\n",
       "      <td>2017-06-02 06:49:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             part        company country       city price                 date\n",
       "8934    68084-172    Twitterbeat  France     Annecy  void  2017-03-18 01:53:38\n",
       "10328  54868-0823  Chatterbridge   Spain  Barcelona  void  2017-06-02 06:49:09"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.price.str.find('v') >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These entries are, as previously mentioned, also missing price values, therefore it is allowed to drop them from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.price.str.find('n') >= 0].index, inplace = True)\n",
    "df.drop(df[df.price.str.find('v') >= 0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can look back at our first and last characters from prices and check if these problems have been solved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$    1425\n",
       "-      56\n",
       "1    3966\n",
       "2    1929\n",
       "3    1630\n",
       "4    2086\n",
       "5    1493\n",
       "6    1403\n",
       "7    1674\n",
       "8    1635\n",
       "9    1407\n",
       "£    1672\n",
       "¥     181\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price.str[0].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       34\n",
       "1      373\n",
       "2      361\n",
       "3      372\n",
       "4      334\n",
       "5      370\n",
       "6      358\n",
       "7      354\n",
       "8      366\n",
       "9      360\n",
       "€    17275\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price.str[-1].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks very good! We can see that we have 56 entries that start with a minus sign, however we believe that such an occurence is not a mistake, but instead it refers to return shippings and cancelations, where our company lost some money as a cost of doing business.\n",
    "\n",
    "Considering that the predominant currency sign here is the EUR (with ~17200 sale entries, vs. the next frequenct USD with only 1425 entries), in the Data Augmentation phase, we will change all these currencies to reflect the EUR value at their specific date. Ultimately, it will probably be a good idea a cohesive currency column, with all values representing the same currency and being `float` structures, such that necessary mathematical operations be performed with ease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Cleaning `date` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will clean our last remaining column, `date`. Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.date.isnull()].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank God, we don't seem to have missing-value issues here.\n",
    "\n",
    "We also need to correct for formatting issues, and since this is a date column, we can almost always expect such errors to appear.\n",
    "\n",
    "Even though we expect `date` to contain unique values for almost every entry, it can still be a good idea to check the frequency counting (ie. value_counts) to see if you can easily spot errors in formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10/04/2017             7\n",
       "2016-04-07             5\n",
       "2018-12-10             2\n",
       "2018-10-21             2\n",
       "2017-04-08             2\n",
       "2018-05-20 07:06:16    2\n",
       "2018-10-13             2\n",
       "2018-12-10             2\n",
       "2016-09-08 05:24:26    1\n",
       "2017-11-27 19:39:50    1\n",
       "2017-10-07 04:19:22    1\n",
       "2017-07-17 06:39:30    1\n",
       "2018-06-21 01:41:24    1\n",
       "2018-09-05 13:56:06    1\n",
       "2016-01-03 02:33:24    1\n",
       "2017-03-25 21:12:38    1\n",
       "2016-12-03 17:33:16    1\n",
       "2016-04-21 13:42:13    1\n",
       "2016-12-25 13:59:13    1\n",
       "2017-07-22 03:11:55    1\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately, we descover two things:\n",
    "    \n",
    "1. The date format, in most of the cases, should follow the string convention `YYYY-MM-DD HH:MM:SS`, which is easy to convert and straightforward to understand.\n",
    "2. We seem to have some inconsistencies in dates, either ___within the format___ or ___with missing hourly times___.\n",
    "\n",
    "Fortunately, cleaning this can be straightforward. We only need to modify the inconsistent format to align with our found date convention, since the missing hours from some dates can automatically be converted to a _00:00:00_ timeframe.\n",
    "\n",
    "We know that our date string convention follows a strict guideline, with cues such as _`-`_ or _`:`_ being always present at specfic parts of the string. At the same time, we know that our date must have a length of exactly 19 characters. We can use this information to scan the entire column for any anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/04/2017 7\n",
      "2016-04-07 5\n",
      "2018-12-10 2\n",
      "2018-10-21  2\n",
      "2017-04-08  2\n",
      "2018-10-13  2\n",
      "2018-12-10  2\n",
      "2018-10-21 1\n",
      "2018-11-17  1\n",
      "2018-11-17 1\n",
      "2017-04-08 1\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the date Series\n",
    "for index, value in df.date.value_counts().iteritems():\n",
    "    if (len(index) < 19):\n",
    "        print(index + ' ' + str(value))\n",
    "    elif (index[4] != '-'):\n",
    "        print(index + ' ' + str(value))\n",
    "    elif (index[7] != '-'):\n",
    "        print(index + ' ' + str(value))\n",
    "    elif (index[10] != ' '):\n",
    "        print(index + ' ' + str(value))\n",
    "    elif (index[13] != ':'):\n",
    "        print(index + ' ' + str(value))\n",
    "    elif (index[16] != ':'):\n",
    "        print(index + ' ' + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that looks good, since only the first type of date must be re-formatted. The other smaller strings, when converted to date objects, will we automatically given an hour time corresponding to midnight. Let us quickly wrangle the erroneous formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.date == '10/04/2017', 'date'] = str(pd.to_datetime('2017-04-10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now try to perform the final conversion of this column from a ___string___ column to a ___date___ column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(df.date, format = '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _This would give off the following error: \"ValueError: time data 2016-06-32 07:22:28 doesn't match format specified\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have unfortuntely received a __ValueError__: it appears that somewhere within our data, we have a date corresponding to the ___32nd of June 2016___... that can't be true. Let's investigate, while remembering that our data is sorted by date, therefore the entry above or below it will show the almost-exact time during which the transaction would have been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>17156-617</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>791.86€</td>\n",
       "      <td>2016-06-32 07:22:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           part     company   country     city    price                 date\n",
       "3539  17156-617  Thoughtmix  Portugal  Amadora  791.86€  2016-06-32 07:22:28"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.date == '2016-06-32 07:22:28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>55856-0003</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>389.89€</td>\n",
       "      <td>2016-06-10 03:26:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0615-7679</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>271.85€</td>\n",
       "      <td>2016-06-10 06:24:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>17156-617</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>791.86€</td>\n",
       "      <td>2016-06-32 07:22:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>525.24€</td>\n",
       "      <td>2016-06-32 08:08:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>76335-006</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>378.85€</td>\n",
       "      <td>2016-06-10 10:02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>55566-2100</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£723.29</td>\n",
       "      <td>2016-06-10 12:01:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part      company         country        city    price  \\\n",
       "3537  55856-0003   Thoughtmix        Portugal     Amadora  389.89€   \n",
       "3538   0615-7679   Thoughtmix        Portugal     Amadora  271.85€   \n",
       "3539   17156-617   Thoughtmix        Portugal     Amadora  791.86€   \n",
       "3540  54868-5165  Shufflebeat        Portugal       Porto  525.24€   \n",
       "3541   76335-006     Buzzbean         Germany  Düsseldorf  378.85€   \n",
       "3542  55566-2100        Zooxo  United Kingdom      London  £723.29   \n",
       "\n",
       "                     date  \n",
       "3537  2016-06-10 03:26:41  \n",
       "3538  2016-06-10 06:24:59  \n",
       "3539  2016-06-32 07:22:28  \n",
       "3540  2016-06-32 08:08:48  \n",
       "3541  2016-06-10 10:02:20  \n",
       "3542  2016-06-10 12:01:15  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[3537, 3538, 3539, 3540, 3541, 3542]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we have two wrong dates within this set of data, both corresponding to the 32nd of June, when clearly it should have been the 10th of June.\n",
    "\n",
    "Since we don't know how many more of those errors are hidden within the data, what we can do is the following: we can convert the `date` column to a Timestamp object column anyway, coercing errors such that, if an erroneous date is present, it should be replaced by `NaN`. Afterwards, since this data is ordered specifically by date, we can fill in the `NaN` values of such dats with the date values of the entries right before them. We lose some small precision in terms of hour time, however we argue that our analysis can tolerate very small alterations in the selling hours of only a few of the date entries. Let us procede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.date.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 erroneous dates which we must fill. Let us do so by taking the date entry which is located right before them in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date.fillna(method = 'ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do we still have missing date values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.date.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears not. Since we knew the indexes of where such a problem was located previously, let's check to see if everything was fixed now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>55856-0003</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>389.89€</td>\n",
       "      <td>2016-06-10 03:26:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0615-7679</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>271.85€</td>\n",
       "      <td>2016-06-10 06:24:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>17156-617</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>791.86€</td>\n",
       "      <td>2016-06-10 06:24:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>525.24€</td>\n",
       "      <td>2016-06-10 06:24:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>76335-006</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>378.85€</td>\n",
       "      <td>2016-06-10 10:02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>55566-2100</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£723.29</td>\n",
       "      <td>2016-06-10 12:01:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part      company         country        city    price  \\\n",
       "3537  55856-0003   Thoughtmix        Portugal     Amadora  389.89€   \n",
       "3538   0615-7679   Thoughtmix        Portugal     Amadora  271.85€   \n",
       "3539   17156-617   Thoughtmix        Portugal     Amadora  791.86€   \n",
       "3540  54868-5165  Shufflebeat        Portugal       Porto  525.24€   \n",
       "3541   76335-006     Buzzbean         Germany  Düsseldorf  378.85€   \n",
       "3542  55566-2100        Zooxo  United Kingdom      London  £723.29   \n",
       "\n",
       "                    date  \n",
       "3537 2016-06-10 03:26:41  \n",
       "3538 2016-06-10 06:24:59  \n",
       "3539 2016-06-10 06:24:59  \n",
       "3540 2016-06-10 06:24:59  \n",
       "3541 2016-06-10 10:02:20  \n",
       "3542 2016-06-10 12:01:15  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[3537, 3538, 3539, 3540, 3541, 3542]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! Now all these consecutive entries (_which should be consecutive in time as well_) are showing the correct date, as we have requested.\n",
    "\n",
    "Once more, let us check df.info() for information regarding number of values and column data types, and we can see that there are no more missing values in our dataset, and we hope to have corrected all the erroneous entries as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20557 entries, 0 to 20567\n",
      "Data columns (total 6 columns):\n",
      "part       20557 non-null object\n",
      "company    20557 non-null object\n",
      "country    20557 non-null object\n",
      "city       20557 non-null object\n",
      "price      20557 non-null object\n",
      "date       20557 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _We have now concluded the Data Cleaning part for our dataset._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task for a data scientists is to combine or enrich data from internal sources with data available from external sources. The purpose of this can be either to fix issues with the data or to make it easier to derive insights from the data.\n",
    "\n",
    "In this part you should enrich your data with data from at least one external source. You may look to part 4 for some  inspiration as to what is required. Your solution should be automated, i.e., you can not ask the reader of your notebook to download any data manually. You should argue why and what you expect to achieve by the enrichments you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When deciding to proceed to the Data Augmentation step here, we need to look back at what exists in our dataset, and try to understand what forms of data, not yet present, would be extremely helpful when moving forward, in order to make strong analysis results in a broad context.\n",
    "\n",
    "Let us look again at how our dataset looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76117-001</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1075.82€</td>\n",
       "      <td>2016-01-02 02:32:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44946-1046</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>412.55€</td>\n",
       "      <td>2016-01-02 04:51:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company country          city     price  \\\n",
       "0  54868-5165  Chatterbridge   Spain     Barcelona   784.79€   \n",
       "1  60505-2867           Lajo  Greece  Thessaloniki   187.99€   \n",
       "2   24385-268      Flipstorm  Greece        Athens   221.73€   \n",
       "3   76117-001    Twitterbeat  France        Annecy  1075.82€   \n",
       "4  44946-1046  Chatterbridge   Spain     Barcelona   412.55€   \n",
       "\n",
       "                 date  \n",
       "0 2016-01-02 00:01:05  \n",
       "1 2016-01-02 00:05:26  \n",
       "2 2016-01-02 00:18:30  \n",
       "3 2016-01-02 02:32:30  \n",
       "4 2016-01-02 04:51:55  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back at the columns that we have, and at their types, we can think about two main directions of augmenting this data:\n",
    "\n",
    "1. We can see that the date column is containing both the dates of the sales, as well as their exact times. For easier processing and day-based comparison of sales, we can add separate columns for the ___date___ and separate columns for the ___time___. \n",
    "\n",
    "2. The `price` column has its currencies in four different possibilites: EUR, USD, GBP and JPY. This is confusing and it does not allow us to perform direct comparisons of business profit. We need to bring the price to a common currency, which will be EUR, since we found out earlier that most entries use this currency. We will be using an external API for currency conversion based on the exact date in which the transaction happened. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first deal with the separation between date and time entries:\n",
    "\n",
    "We will rename our `date` column to `datetime`, to represent the fact that the full timestamp is stored in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = df.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we can apply a _split_ function to the timestamp to extract separately the date elements and the time elements from each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.date.apply(lambda row: str(row).split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = df.datetime.apply(lambda row: str(row).split(' ')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally here, we want to re-arrange the columns in the dataframe so that the full `datetime` column comes before the newly-separated `date` and `time` entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['part', 'company', 'country', 'city', 'price', 'datetime', 'date', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>00:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76117-001</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1075.82€</td>\n",
       "      <td>2016-01-02 02:32:30</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>02:32:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44946-1046</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>412.55€</td>\n",
       "      <td>2016-01-02 04:51:55</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>04:51:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company country          city     price  \\\n",
       "0  54868-5165  Chatterbridge   Spain     Barcelona   784.79€   \n",
       "1  60505-2867           Lajo  Greece  Thessaloniki   187.99€   \n",
       "2   24385-268      Flipstorm  Greece        Athens   221.73€   \n",
       "3   76117-001    Twitterbeat  France        Annecy  1075.82€   \n",
       "4  44946-1046  Chatterbridge   Spain     Barcelona   412.55€   \n",
       "\n",
       "             datetime        date      time  \n",
       "0 2016-01-02 00:01:05  2016-01-02  00:01:05  \n",
       "1 2016-01-02 00:05:26  2016-01-02  00:05:26  \n",
       "2 2016-01-02 00:18:30  2016-01-02  00:18:30  \n",
       "3 2016-01-02 02:32:30  2016-01-02  02:32:30  \n",
       "4 2016-01-02 04:51:55  2016-01-02  04:51:55  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! That was the internal augmentation part for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us look at how to convert from various price strings to currency-specific price numbers:\n",
    "\n",
    "We will use the API provided by https://exchangeratesapi.io/, while using their website documentation to be able to understand the JSON object structure retrieved from the API.\n",
    "\n",
    "We have found that, by linking the website domain https://api.exchangeratesapi.io/ with a specific date parameter, we can retrieve historical data regarding currency rates. Moreover, by specifying the `base` parameter, we can provide the original currency which we want to convert further to other currencies. Also, through specifying `symbols`, we list the currencies that we are interested to convert into.\n",
    "\n",
    "Below, we will write a function that will take a price (_containing the currency symbol inside it_) and a historical date, and will return the converted price of that sale in EUR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take about 3-4 minutes to execute, due to the large number of API calls\n",
    "\n",
    "def retrieve_converted_prices(price, date):\n",
    "    date = str(date)\n",
    "    \n",
    "    base = 'EUR'      # Initially, we will assume the base currency to be EUR\n",
    "    symbols = 'EUR'   # We will also set the retrieved currency to be EUR, to check later whether there is any need for price conversion of an entry or not\n",
    "    \n",
    "    currency_rate = 1.0 # For EUR entries, we won't need to convert them further, so we will just set an initial currency rate of 1\n",
    "    \n",
    "    if (price[0] == '$'):\n",
    "        base = 'USD'\n",
    "    elif (price[0] == '£'):\n",
    "        base = 'GBP'\n",
    "    elif (price[0] == '¥'):\n",
    "        base = 'JPY'\n",
    "    \n",
    "    if (base != symbols):    # If the base currency and the currency to convert into are not both EUR at the same time,...\n",
    "        params = {'base': base, 'symbols': symbols}\n",
    "        response = requests.get('https://api.exchangeratesapi.io/' + date, params = params)\n",
    "        currency_rate = response.json()['rates']['EUR']\n",
    "        \n",
    "        # If base and symbols are not the same, we can be sure that it is a currency different than EUR, \n",
    "        # and then the symbol for all the other 3 currencies are found in the first character of the string. We need to remove that to have the numerical currency value.\n",
    "        \n",
    "        converted_price = float(price[1:]) * currency_rate\n",
    "        converted_price = np.round(converted_price, 2) # We will round all currency conversions to 2 decimals, since this is the precision with which we received the original price data \n",
    "        \n",
    "    else:\n",
    "        # Otherwise, it means that the currency is already in EUR, and we need to get its numerical value by removing the last string character\n",
    "        converted_price = float(price[:-1])\n",
    "        \n",
    "    return converted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try and apply this function efficiently to each of our dataset's rows, by using the `apply()` method for quick iteration. We will name our new column of converted prices (returned as __floats!__) as `price_eur`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-c3c1375894d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_eur'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretrieve_converted_prices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6002\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6003\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6004\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    243\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-c3c1375894d8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_eur'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretrieve_converted_prices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-da2642595794>\u001b[0m in \u001b[0;36mretrieve_converted_prices\u001b[0;34m(price, date)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# If the base currency and the currency to convert into are not both EUR at the same time,...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'base'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'symbols'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api.exchangeratesapi.io/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mcurrency_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EUR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['price_eur'] = df.apply(lambda row: retrieve_converted_prices(row.price, row.date), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will take 3-4 minutes to complete due to the large number of dates and currencies that we have to compare against. \n",
    "\n",
    "After it is done, let us check for the final result of the `price_eur` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The external augmentation done by the API seems to have worked well! \n",
    "\n",
    "Finally, since we already have the converted price data in `price_eur`, let us remove the old column containing price strings, and rearrange the columns as they were before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'price', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['part', 'company', 'country', 'city', 'price_eur', 'datetime', 'date', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _We have now completed the Data Enhancement part for our dataset._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:14:56.926221Z",
     "start_time": "2019-10-08T18:14:56.302894Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('transaction.sqlite')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:14:14.176587Z",
     "start_time": "2019-10-08T18:14:14.062890Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6b266b03b18f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'transactions'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# c.execute(\"SELECT * FROM sqlite_master WHERE type = 'table' AND name NOT LIKE 'sqlite_%';\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# print(c.fetchall())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_sql('transactions', conn, if_exists = 'replace', index = True)\n",
    "# c.execute(\"SELECT * FROM sqlite_master WHERE type = 'table' AND name NOT LIKE 'sqlite_%';\")\n",
    "# print(c.fetchall())\n",
    "c.execute(\"SELECT * FROM transactions\")\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:14:59.005718Z",
     "start_time": "2019-10-08T18:14:58.952801Z"
    }
   },
   "outputs": [],
   "source": [
    "#Solution 1:\n",
    "c.execute('SELECT *, SUM(price_eur) FROM transactions GROUP BY company ORDER BY SUM(price_eur) DESC')\n",
    "c.fetchall()\n",
    "data = pd.DataFrame(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:15:02.326775Z",
     "start_time": "2019-10-08T18:15:02.294894Z"
    }
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \"(\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d2b4f5858890>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Solution 2:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT price_eur, company, datetime LAG (price_eur, 1, 0) OVER (PARTITION BY company ORDER BY datetime) prev_price_eur FROM transactions WHERE prev_price_eur > price_eur\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# data = pd.DataFrame(c.fetchall())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: near \"(\": syntax error"
     ]
    }
   ],
   "source": [
    "#Solution 2:\n",
    "\n",
    "c.execute(\"SELECT price_eur, company, datetime LAG (price_eur, 1, 0) OVER (PARTITION BY company ORDER BY datetime) prev_price_eur FROM transactions WHERE prev_price_eur > price_eur\")\n",
    "c.fetchall()\n",
    "# data = pd.DataFrame(c.fetchall())\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
